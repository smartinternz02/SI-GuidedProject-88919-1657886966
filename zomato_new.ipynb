{"cells":[{"cell_type":"code","execution_count":null,"id":"787ec031","metadata":{"id":"787ec031"},"outputs":[],"source":["#import Libraries\n","\n","import numpy as np\n","import pandas as pd\n","import re"]},{"cell_type":"code","execution_count":null,"id":"f24ebfaf","metadata":{"id":"f24ebfaf","outputId":"23997a6b-ff2e-4837-e97c-1e425f9affff"},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Rated 4.0', 'RATED\\n  A beautiful place to dine in.The interiors take you back to the Mughal era. The lightings are just perfect.We went there on the occasion of Christmas and so they had only limited items available. But the taste and service was not compromised at all.The only complaint is that the breads could have been better.Would surely like to come here again.'), ('Rated 4.0', 'RATED\\n  I was here for dinner with my family on a weekday. The restaurant was completely empty. Ambience is good with some good old hindi music. Seating arrangement are good too. We ordered masala papad, panner and baby corn starters, lemon and corrionder soup, butter roti, olive and chilli paratha. Food was fresh and good, service is good too. Good for family hangout.\\nCheers'), ('Rated 2.0', 'RATED\\n  Its a restaurant near to Banashankari BDA. Me along with few of my office friends visited to have buffet but unfortunately they only provide veg buffet. On inquiring they said this place is mostly visited by vegetarians. Anyways we ordered ala carte items which took ages to come. Food was ok ok. Definitely not visiting anymore.'), ('Rated 4.0', 'RATED\\n  We went here on a weekend and one of us had the buffet while two of us took Ala Carte. Firstly the ambience and service of this place is great! The buffet had a lot of items and the good was good. We had a Pumpkin Halwa intm the dessert which was amazing. Must try! The kulchas are great here. Cheers!'), ('Rated 5.0', 'RATED\\n  The best thing about the place is itÃ\\x83Ã\\x83Ã\\x82Ã\\x82Ã\\x83Ã\\x82Ã\\x82Ã\\x92s ambiance. Second best thing was yummy ? food. We try buffet and buffet food was not disappointed us.\\nTest ?. ?? ?? ?? ?? ??\\nQuality ?. ??????????.\\nService: Staff was very professional and friendly.\\n\\nOverall experience was excellent.\\n\\nsubirmajumder85.wixsite.com'), ('Rated 5.0', 'RATED\\n  Great food and pleasant ambience. Expensive but Coll place to chill and relax......\\n\\nService is really very very good and friendly staff...\\n\\nFood : 5/5\\nService : 5/5\\nAmbience :5/5\\nOverall :5/5'), ('Rated 4.0', 'RATED\\n  Good ambience with tasty food.\\nCheese chilli paratha with Bhutta palak methi curry is a good combo.\\nLemon Chicken in the starters is a must try item.\\nEgg fried rice was also quite tasty.\\nIn the mocktails, recommend \"Alice in Junoon\". Do not miss it.'), ('Rated 4.0', 'RATED\\n  You canÃ\\x83Ã\\x83Ã\\x82Ã\\x82Ã\\x83Ã\\x82Ã\\x82Ã\\x92t go wrong with Jalsa. Never been a fan of their buffet and thus always order alacarteÃ\\x83Ã\\x83Ã\\x82Ã\\x82Ã\\x83Ã\\x82Ã\\x82Ã\\x92. Service at times can be on the slower side but food is worth the wait.'), ('Rated 5.0', 'RATED\\n  Overdelighted by the service and food provided at this place. A royal and ethnic atmosphere builds a strong essence of being in India and also the quality and taste of food is truly authentic. I would totally recommend to visit this place once.'), ('Rated 4.0', 'RATED\\n  The place is nice and comfortable. Food wise all jalea outlets maintain a good standard. The soya chaap was a standout dish. Clearly one of trademark dish as per me and a must try.\\n\\nThe only concern is the parking. It very congested and limited to just 5cars. The basement parking is very steep and makes it cumbersome'), ('Rated 4.0', 'RATED\\n  The place is nice and comfortable. Food wise all jalea outlets maintain a good standard. The soya chaap was a standout dish. Clearly one of trademark dish as per me and a must try.\\n\\nThe only concern is the parking. It very congested and limited to just 5cars. The basement parking is very steep and makes it cumbersome'), ('Rated 4.0', 'RATED\\n  The place is nice and comfortable. Food wise all jalea outlets maintain a good standard. The soya chaap was a standout dish. Clearly one of trademark dish as per me and a must try.\\n\\nThe only concern is the parking. It very congested and limited to just 5cars. The basement parking is very steep and makes it cumbersome')]\n"]}],"source":["#First import the dataset in the dataset variable\n","#data_review variable contains the reveiws and ratings \n","dataset = pd.read_csv(\"zomato.csv\")\n","data_review = dataset['reviews_list']\n","\n","print(dataset['reviews_list'][0])"]},{"cell_type":"code","execution_count":null,"id":"b660c854","metadata":{"id":"b660c854"},"outputs":[],"source":["x = []\n","y = []"]},{"cell_type":"code","execution_count":null,"id":"c689df98","metadata":{"id":"c689df98"},"outputs":[],"source":["# here we tokenize the rating string and the review string\n","#loop over all the rows\n","for row_num in range(0,51717):\n","    # split the revie text at '()\n","    lst = data_review[row_num].split(\"('\")\n","    for i in lst:\n","        if len(i) > 5:\n","            if i.find(\"',\") != -1:\n","                single_rev = i.split(\"',\")\n","                if len(single_rev[0]) > 2:\n","                    x.append(single_rev[0])\n","                if len(single_rev[1]) > 2:    \n","                    y.append(single_rev[1])\n","\n"]},{"cell_type":"code","execution_count":null,"id":"95545bfe","metadata":{"id":"95545bfe"},"outputs":[],"source":["#!pip install nltk"]},{"cell_type":"code","execution_count":null,"id":"b8223c1c","metadata":{"id":"b8223c1c","outputId":"4329987e-0714-4e11-8229-ea99780dc126"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["#Import the Librariesimport re \n","import nltk\n","nltk.download(\"stopwords\") \n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","ps = PorterStemmer()\n"]},{"cell_type":"code","execution_count":null,"id":"0cdfd667","metadata":{"id":"0cdfd667"},"outputs":[],"source":["# to store the final rating\n","rating_final = []\n","# to store cleaned revies\n","review_final = []\n"]},{"cell_type":"code","execution_count":null,"id":"3b639a0d","metadata":{"id":"3b639a0d"},"outputs":[],"source":["# the rating string contains words and numbers \n","# so we tokenize the numbers only from it and change into float\n","# for rartings below 2.5 we store the rating as poor\n","# for ratings between 2.5 and 3.5 the rating as average\n","# for ratings more than 3.5 tha rating stored as good\n","\n","for loop in range(0,40000):\n","    data_x = x[loop]\n","    data_x = re.sub('[a-zA-Z]', \" \", data_x)\n","    data_x = data_x.split()\n","    data_x = ''.join(data_x)\n","    data_x = float(data_x)\n","    if data_x < 2.5:\n","        rating_final.append(\"poor\") #poor\n","    elif data_x >= 2.5 and data_x <= 3.5 :    \n","        rating_final.append(\"average\") # average\n","    elif data_x > 3.5:\n","        rating_final.append(\"good\") #good\n","        "]},{"cell_type":"code","execution_count":null,"id":"fa8815ea","metadata":{"id":"fa8815ea","outputId":"1e69d796-e51e-4281-d65b-328a794c6526"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sklearn in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (0.0)\n","Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from sklearn) (0.24.2)\n","Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n","Requirement already satisfied: scipy>=0.19.1 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->sklearn) (1.4.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->sklearn) (3.0.0)\n","Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hp\\anaconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->sklearn) (1.18.5)\n"]}],"source":["!pip install sklearn"]},{"cell_type":"code","execution_count":null,"id":"bc115ca5","metadata":{"id":"bc115ca5"},"outputs":[],"source":["# label encode the Ratings and OneHotEncode for the classification        \n","\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","rating_final = le.fit_transform(rating_final)\n","\n","rating_final = np.array(rating_final)\n","rating_final = np.expand_dims(rating_final, axis=1)\n","        \n","from sklearn.preprocessing import OneHotEncoder\n","one = OneHotEncoder()\n","rates = one.fit_transform(rating_final).toarray()"]},{"cell_type":"code","execution_count":null,"id":"bdc69493","metadata":{"id":"bdc69493"},"outputs":[],"source":["# Here the unnecessary stop words from the reviews lists\n","# Stemming operations are also done here \n","\n","for loop in range(0,40000) : \n","    data_y = y[loop]\n","    data_y = re.sub('[^a-zA-Z]', \" \", data_y)\n","    data_y = data_y.lower()\n","    data_y = data_y.split()\n","    data_y = [ps.stem(word) for word in data_y if not word in set(stopwords.words('english'))]\n","    data_y = ' '.join(data_y)\n","    review_final.append(data_y)"]},{"cell_type":"code","execution_count":null,"id":"0a2262f5","metadata":{"id":"0a2262f5"},"outputs":[],"source":["# count vectorize the reviews according to the unique words    \n","                    \n","from sklearn.feature_extraction.text import CountVectorizer\n","cv = CountVectorizer(max_features = 20000)\n","x_final = cv.fit_transform(review_final).toarray()"]},{"cell_type":"code","execution_count":null,"id":"a5e74e06","metadata":{"id":"a5e74e06"},"outputs":[],"source":["# saving the vectorizer which would be used as dictionary.\n","import pickle\n","pickle.dump(cv, open('cv.pkl','wb'))"]},{"cell_type":"code","execution_count":null,"id":"5fb4497c","metadata":{"id":"5fb4497c"},"outputs":[],"source":["# Split the data into test and train sets\n","\n","from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(x_final,rates, test_size = 0.2, random_state = 0)  "]},{"cell_type":"code","execution_count":null,"id":"a4defbe9","metadata":{"id":"a4defbe9","outputId":"c7e5d2a0-0997-4b50-e649-26325936ebbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","250/250 [==============================] - 215s 861ms/step - loss: 0.4887 - accuracy: 0.8319\n","Epoch 2/20\n","250/250 [==============================] - 223s 891ms/step - loss: 0.1400 - accuracy: 0.9527\n","Epoch 3/20\n","250/250 [==============================] - 951s 4s/step - loss: 0.0939 - accuracy: 0.9681\n","Epoch 4/20\n","250/250 [==============================] - 251s 1s/step - loss: 0.0830 - accuracy: 0.9712\n","Epoch 5/20\n","118/250 [=============>................] - ETA: 2:10 - loss: 0.0767 - accuracy: 0.9729"]}],"source":["# adding the neuron layers \n","# the units in the input layers is equal to the number of unique words\n","# taken three deeper layers of 2000 units each\n","# Relu as activation in the hidden layers\n","# the output layer has 3 units as the one hot encoding has 3 columns\n","# the classification is in categorical\n","\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","model = Sequential()\n","model.add(Dense(units = 13264, kernel_initializer = 'random_uniform', activation = 'relu'))\n","model.add(Dense(units = 2000, kernel_initializer = 'random_uniform', activation = 'relu'))\n","model.add(Dense(units = 2000, kernel_initializer = 'random_uniform', activation = 'relu'))\n","model.add(Dense(units = 2000, kernel_initializer = 'random_uniform', activation = 'relu'))\n","model.add(Dense(units = 3, kernel_initializer = 'random_uniform', activation = 'softmax'))\n","model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","model.fit(x_train,y_train,batch_size = 128,epochs = 20)"]},{"cell_type":"code","execution_count":null,"id":"8673c881","metadata":{"id":"8673c881","outputId":"a4acac20-a98f-4add-c460-0872311df2a2"},"outputs":[{"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-f3204583ddc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# testing the prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m\"The food is okay. average place \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["# testing the prediction\n","\n","y_pred = model.predict(x_test)\n","\n","text =  \"The food is okay. average place \"\n","text = re.sub('[^a-zA-Z]', ' ',text)\n","text = text.lower()\n","text = text.split()\n","text = [ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n","text = ' '.join(text)\n","\n","y_p = model.predict(cv.transform([text]))"]},{"cell_type":"code","execution_count":null,"id":"c1720c38","metadata":{"id":"c1720c38"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"},"colab":{"name":"Untitled.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":5}